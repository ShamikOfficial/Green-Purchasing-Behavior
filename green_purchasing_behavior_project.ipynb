{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Green Purchasing Behavior Cube - NoSQL Project\n",
    "\n",
    "## Project Overview\n",
    "This project implements a custom JSON parser and NoSQL database operations to analyze the relationship between consumer spending on sustainable foods and economic factors like income and jobs.\n",
    "\n",
    "## Team: Individual Project (Shamik Basu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Extended JSON Parser\n",
    "\n",
    "Extending the sample code to handle:\n",
    "- Arrays\n",
    "- Nested objects and arrays\n",
    "- Boolean and null values\n",
    "- Complex JSON structures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Extended JSON Parser:\n",
      "==================================================\n",
      "Test 1 - Simple object: {'name': 'john', 'age': 25.3, 'gender': 'male'}\n",
      "Test 2 - Nested object: {'person': {'name': 'john', 'age': 25}, 'city': 'LA'}\n",
      "Test 3 - Array: [1, 2, 3, 'hello', True, None]\n",
      "Test 4 - Array of objects: [{'id': 1, 'name': 'Alice'}, {'id': 2, 'name': 'Bob'}]\n",
      "Test 5 - Complex nested: {'data': [{'county': 'LA', 'spend': 1000}, {'county': 'NY', 'spend': 2000}], 'year': 2023}\n"
     ]
    }
   ],
   "source": [
    "# Extended JSON Parser Implementation\n",
    "# Based on sample code, extended to handle arrays, nested structures, booleans, and null\n",
    "\n",
    "import re\n",
    "\n",
    "def parse_string(str):\n",
    "    \"\"\"Parse a string value from JSON\"\"\"\n",
    "    str = str.lstrip()\n",
    "    assert(str[0] == '\"'), f\"Expected '\\\"' but found '{str[0]}'\"\n",
    "    str = str[1:]  # skip the start quote\n",
    "    \n",
    "    # Handle escaped characters (basic support)\n",
    "    mystr = \"\"\n",
    "    i = 0\n",
    "    while i < len(str):\n",
    "        if str[i] == '\\\\' and i + 1 < len(str):\n",
    "            # Handle escape sequences\n",
    "            if str[i+1] == 'n':\n",
    "                mystr += '\\n'\n",
    "                i += 2\n",
    "            elif str[i+1] == 't':\n",
    "                mystr += '\\t'\n",
    "                i += 2\n",
    "            elif str[i+1] == '\\\\':\n",
    "                mystr += '\\\\'\n",
    "                i += 2\n",
    "            elif str[i+1] == '\"':\n",
    "                mystr += '\"'\n",
    "                i += 2\n",
    "            else:\n",
    "                mystr += str[i]\n",
    "                i += 1\n",
    "        elif str[i] == '\"':\n",
    "            # End of string\n",
    "            rest = str[i + 1:]\n",
    "            return mystr, rest\n",
    "        else:\n",
    "            mystr += str[i]\n",
    "            i += 1\n",
    "    \n",
    "    raise ValueError('Unterminated string')\n",
    "\n",
    "def parse_number(str):\n",
    "    \"\"\"Parse a number (int or float) from JSON\"\"\"\n",
    "    str = str.lstrip()\n",
    "    \n",
    "    chs = ''\n",
    "    is_float = False\n",
    "    i = 0\n",
    "    for ch in str:\n",
    "        if (ch.isdigit() or ch == '.' or ch == '-' or ch == '+' or ch == 'e' or ch == 'E'):\n",
    "            if ch == '.':\n",
    "                is_float = True\n",
    "            chs += ch\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    if len(chs) == 0:\n",
    "        raise ValueError('Expected number but found nothing')\n",
    "    \n",
    "    str = str[i:]\n",
    "    value = float(chs) if is_float else int(chs)\n",
    "    return value, str\n",
    "\n",
    "def parse_boolean(str):\n",
    "    \"\"\"Parse boolean values (true/false)\"\"\"\n",
    "    str = str.lstrip()\n",
    "    if str.startswith('true'):\n",
    "        return True, str[4:]\n",
    "    elif str.startswith('false'):\n",
    "        return False, str[5:]\n",
    "    else:\n",
    "        raise ValueError('Expected boolean but found something else')\n",
    "\n",
    "def parse_null(str):\n",
    "    \"\"\"Parse null value\"\"\"\n",
    "    str = str.lstrip()\n",
    "    if str.startswith('null'):\n",
    "        return None, str[4:]\n",
    "    else:\n",
    "        raise ValueError('Expected null but found something else')\n",
    "\n",
    "def parse_colon(str):\n",
    "    \"\"\"Consume a colon ':'\"\"\"\n",
    "    str = str.lstrip()\n",
    "    assert(str[0] == ':'), f\"Expected ':' but found '{str[0]}'\"\n",
    "    return str[1:]\n",
    "\n",
    "def parse_value(str):\n",
    "    \"\"\"Parse any JSON value (object, array, string, number, boolean, null)\"\"\"\n",
    "    str = str.lstrip()\n",
    "    \n",
    "    if len(str) == 0:\n",
    "        raise ValueError('Unexpected end of string')\n",
    "    \n",
    "    if str[0] == '{':\n",
    "        return parse_object(str)\n",
    "    elif str[0] == '[':\n",
    "        return parse_array(str)\n",
    "    elif str[0] == '\"':\n",
    "        return parse_string(str)\n",
    "    elif str[0] == '-' or str[0].isdigit():\n",
    "        return parse_number(str)\n",
    "    elif str.startswith('true') or str.startswith('false'):\n",
    "        return parse_boolean(str)\n",
    "    elif str.startswith('null'):\n",
    "        return parse_null(str)\n",
    "    else:\n",
    "        raise ValueError(f'Unexpected character: {str[0]}')\n",
    "\n",
    "def parse_object(str):\n",
    "    \"\"\"Parse a JSON object (dictionary) - extended to handle nested structures\"\"\"\n",
    "    str = str.lstrip()\n",
    "    assert(str[0] == '{'), f\"Expected '{{' but found '{str[0]}'\"\n",
    "    str = str[1:]  # skip {\n",
    "    \n",
    "    obj = {}\n",
    "    \n",
    "    while True:\n",
    "        str = str.lstrip()\n",
    "        \n",
    "        if len(str) == 0:\n",
    "            raise ValueError('Expecting \"}\" but reached the end of string!')\n",
    "        elif str[0] == '}':  # end of json object\n",
    "            str = str[1:]  # consume '}'\n",
    "            return obj, str\n",
    "        elif str[0] == ',':\n",
    "            str = str[1:]  # skip ','\n",
    "        else:  # ready for a new key-value pair\n",
    "            key, str = parse_string(str)\n",
    "            str = parse_colon(str)  # skip colon\n",
    "            value, str = parse_value(str)  # parse any type of value\n",
    "            obj[key] = value\n",
    "\n",
    "def parse_array(str):\n",
    "    \"\"\"Parse a JSON array (list) - handles nested structures\"\"\"\n",
    "    str = str.lstrip()\n",
    "    assert(str[0] == '['), f\"Expected '[' but found '{str[0]}'\"\n",
    "    str = str[1:]  # skip [\n",
    "    \n",
    "    arr = []\n",
    "    \n",
    "    while True:\n",
    "        str = str.lstrip()\n",
    "        \n",
    "        if len(str) == 0:\n",
    "            raise ValueError('Expecting \"]\" but reached the end of string!')\n",
    "        elif str[0] == ']':  # end of array\n",
    "            str = str[1:]  # consume ']'\n",
    "            return arr, str\n",
    "        elif str[0] == ',':\n",
    "            str = str[1:]  # skip ','\n",
    "        else:  # ready for a new value\n",
    "            value, str = parse_value(str)  # parse any type of value\n",
    "            arr.append(value)\n",
    "\n",
    "def json_load(json_str):\n",
    "    \"\"\"Main function to load JSON string into Python object\"\"\"\n",
    "    json_str = json_str.strip()\n",
    "    value, rest = parse_value(json_str)\n",
    "    rest = rest.strip()\n",
    "    if len(rest) > 0:\n",
    "        raise ValueError(f'Unexpected content after JSON: {rest[:20]}')\n",
    "    return value\n",
    "\n",
    "# Test the extended parser\n",
    "print(\"Testing Extended JSON Parser:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test 1: Simple object\n",
    "test1 = '{\"name\": \"john\", \"age\": 25.3, \"gender\": \"male\"}'\n",
    "result1 = json_load(test1)\n",
    "print(\"Test 1 - Simple object:\", result1)\n",
    "\n",
    "# Test 2: Nested object\n",
    "test2 = '{\"person\": {\"name\": \"john\", \"age\": 25}, \"city\": \"LA\"}'\n",
    "result2 = json_load(test2)\n",
    "print(\"Test 2 - Nested object:\", result2)\n",
    "\n",
    "# Test 3: Array\n",
    "test3 = '[1, 2, 3, \"hello\", true, null]'\n",
    "result3 = json_load(test3)\n",
    "print(\"Test 3 - Array:\", result3)\n",
    "\n",
    "# Test 4: Array of objects\n",
    "test4 = '[{\"id\": 1, \"name\": \"Alice\"}, {\"id\": 2, \"name\": \"Bob\"}]'\n",
    "result4 = json_load(test4)\n",
    "print(\"Test 4 - Array of objects:\", result4)\n",
    "\n",
    "# Test 5: Complex nested structure\n",
    "test5 = '{\"data\": [{\"county\": \"LA\", \"spend\": 1000}, {\"county\": \"NY\", \"spend\": 2000}], \"year\": 2023}'\n",
    "result5 = json_load(test5)\n",
    "print(\"Test 5 - Complex nested:\", result5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Collection/DataFrame Structure\n",
    "\n",
    "Implementing a collection structure to store JSON documents (similar to MongoDB collections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Collection Class:\n",
      "==================================================\n",
      "Collection: Collection(name='test_collection', documents=2)\n",
      "Documents: [{'name': 'Alice', 'age': 30}, {'name': 'Bob', 'age': 25}]\n"
     ]
    }
   ],
   "source": [
    "# Collection class to store JSON documents (similar to MongoDB collections)\n",
    "\n",
    "class Collection:\n",
    "    \"\"\"A collection class to store and manipulate JSON documents\"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.documents = []  # List of dictionaries (JSON objects)\n",
    "    \n",
    "    def insert(self, document):\n",
    "        \"\"\"Insert a document (dictionary) into the collection\"\"\"\n",
    "        if isinstance(document, dict):\n",
    "            self.documents.append(document)\n",
    "        else:\n",
    "            raise TypeError(\"Document must be a dictionary\")\n",
    "    \n",
    "    def insert_many(self, documents):\n",
    "        \"\"\"Insert multiple documents into the collection\"\"\"\n",
    "        for doc in documents:\n",
    "            self.insert(doc)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.documents)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.documents[index]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.documents)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Collection(name='{self.name}', documents={len(self.documents)})\"\n",
    "    \n",
    "    def to_list(self):\n",
    "        \"\"\"Return all documents as a list\"\"\"\n",
    "        return self.documents.copy()\n",
    "\n",
    "# Test Collection\n",
    "print(\"Testing Collection Class:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "collection = Collection(\"test_collection\")\n",
    "collection.insert({\"name\": \"Alice\", \"age\": 30})\n",
    "collection.insert({\"name\": \"Bob\", \"age\": 25})\n",
    "print(f\"Collection: {collection}\")\n",
    "print(f\"Documents: {collection.to_list()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Core Operations\n",
    "\n",
    "Implementing filtering, projection, group by, aggregation, and join operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Core Operations:\n",
      "==================================================\n",
      "Original collection:\n",
      "  {'county': 'LA', 'spend': 1000, 'year': 2023}\n",
      "  {'county': 'NY', 'spend': 2000, 'year': 2023}\n",
      "  {'county': 'LA', 'spend': 1500, 'year': 2024}\n",
      "  {'county': 'NY', 'spend': 2500, 'year': 2024}\n",
      "\n",
      "1. Filtering (spend > 1500):\n",
      "  {'county': 'NY', 'spend': 2000, 'year': 2023}\n",
      "  {'county': 'NY', 'spend': 2500, 'year': 2024}\n",
      "\n",
      "2. Projection (county, spend):\n",
      "  {'county': 'LA', 'spend': 1000}\n",
      "  {'county': 'NY', 'spend': 2000}\n",
      "  {'county': 'LA', 'spend': 1500}\n",
      "  {'county': 'NY', 'spend': 2500}\n",
      "\n",
      "3. Group by county:\n",
      "  LA: 2 documents\n",
      "  NY: 2 documents\n",
      "\n",
      "4. Aggregation (sum of spend by county):\n",
      "  {'county': 'LA', 'sum(spend)': 2500}\n",
      "  {'county': 'NY', 'sum(spend)': 4500}\n",
      "\n",
      "5. Join:\n",
      "  {'county': 'LA', 'population': 10000000, 'unemployment': 5.2}\n",
      "  {'county': 'NY', 'population': 8000000, 'unemployment': 4.8}\n"
     ]
    }
   ],
   "source": [
    "# Operation 1: Filtering\n",
    "def filter_collection(collection, condition_func):\n",
    "    \"\"\"\n",
    "    Filter documents in a collection based on a condition function\n",
    "    \n",
    "    Args:\n",
    "        collection: Collection object\n",
    "        condition_func: Function that takes a document and returns True/False\n",
    "    \n",
    "    Returns:\n",
    "        New Collection with filtered documents\n",
    "    \"\"\"\n",
    "    filtered = Collection(f\"{collection.name}_filtered\")\n",
    "    for doc in collection:\n",
    "        if condition_func(doc):\n",
    "            filtered.insert(doc.copy())\n",
    "    return filtered\n",
    "\n",
    "# Operation 2: Projection\n",
    "def project_collection(collection, fields):\n",
    "    \"\"\"\n",
    "    Project (select) specific fields from documents\n",
    "    \n",
    "    Args:\n",
    "        collection: Collection object\n",
    "        fields: List of field names to select\n",
    "    \n",
    "    Returns:\n",
    "        New Collection with projected documents\n",
    "    \"\"\"\n",
    "    projected = Collection(f\"{collection.name}_projected\")\n",
    "    for doc in collection:\n",
    "        new_doc = {}\n",
    "        for field in fields:\n",
    "            if field in doc:\n",
    "                new_doc[field] = doc[field]\n",
    "        projected.insert(new_doc)\n",
    "    return projected\n",
    "\n",
    "# Operation 3: Group By\n",
    "def group_by(collection, group_key):\n",
    "    \"\"\"\n",
    "    Group documents by a key\n",
    "    \n",
    "    Args:\n",
    "        collection: Collection object\n",
    "        group_key: Field name to group by\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary where keys are group values and values are lists of documents\n",
    "    \"\"\"\n",
    "    groups = {}\n",
    "    for doc in collection:\n",
    "        if group_key in doc:\n",
    "            key_value = doc[group_key]\n",
    "            if key_value not in groups:\n",
    "                groups[key_value] = []\n",
    "            groups[key_value].append(doc)\n",
    "    return groups\n",
    "\n",
    "# Operation 4: Aggregation\n",
    "def aggregate(collection, group_key, agg_field, agg_func):\n",
    "    \"\"\"\n",
    "    Group by a key and apply an aggregation function to a field\n",
    "    \n",
    "    Args:\n",
    "        collection: Collection object\n",
    "        group_key: Field name to group by\n",
    "        agg_field: Field name to aggregate\n",
    "        agg_func: Aggregation function (e.g., 'sum', 'avg', 'max', 'min', 'count')\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries with group_key and aggregated value\n",
    "    \"\"\"\n",
    "    groups = group_by(collection, group_key)\n",
    "    results = []\n",
    "    \n",
    "    for key_value, docs in groups.items():\n",
    "        values = [doc[agg_field] for doc in docs if agg_field in doc]\n",
    "        \n",
    "        if len(values) == 0:\n",
    "            continue\n",
    "            \n",
    "        if agg_func == 'sum':\n",
    "            agg_value = sum(values)\n",
    "        elif agg_func == 'avg':\n",
    "            agg_value = sum(values) / len(values)\n",
    "        elif agg_func == 'max':\n",
    "            agg_value = max(values)\n",
    "        elif agg_func == 'min':\n",
    "            agg_value = min(values)\n",
    "        elif agg_func == 'count':\n",
    "            agg_value = len(values)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown aggregation function: {agg_func}\")\n",
    "        \n",
    "        results.append({group_key: key_value, f\"{agg_func}({agg_field})\": agg_value})\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Operation 5: Join\n",
    "def join_collections(collection1, collection2, key1, key2):\n",
    "    \"\"\"\n",
    "    Join two collections on specified keys\n",
    "    \n",
    "    Args:\n",
    "        collection1: First Collection object\n",
    "        collection2: Second Collection object\n",
    "        key1: Key in collection1 to join on\n",
    "        key2: Key in collection2 to join on\n",
    "    \n",
    "    Returns:\n",
    "        New Collection with joined documents\n",
    "    \"\"\"\n",
    "    joined = Collection(f\"{collection1.name}_join_{collection2.name}\")\n",
    "    \n",
    "    # Build index on collection2 for faster lookup\n",
    "    index = {}\n",
    "    for doc2 in collection2:\n",
    "        if key2 in doc2:\n",
    "            key_value = doc2[key2]\n",
    "            if key_value not in index:\n",
    "                index[key_value] = []\n",
    "            index[key_value].append(doc2)\n",
    "    \n",
    "    # Perform join\n",
    "    for doc1 in collection1:\n",
    "        if key1 in doc1:\n",
    "            key_value = doc1[key1]\n",
    "            if key_value in index:\n",
    "                for doc2 in index[key_value]:\n",
    "                    # Merge documents\n",
    "                    merged = doc1.copy()\n",
    "                    # Add fields from doc2, avoiding conflicts by prefixing\n",
    "                    for k, v in doc2.items():\n",
    "                        if k != key2:  # Don't duplicate the join key\n",
    "                            if k in merged:\n",
    "                                merged[f\"{collection2.name}_{k}\"] = v\n",
    "                            else:\n",
    "                                merged[k] = v\n",
    "                    joined.insert(merged)\n",
    "    \n",
    "    return joined\n",
    "\n",
    "# Test operations\n",
    "print(\"Testing Core Operations:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create test collection\n",
    "test_coll = Collection(\"test\")\n",
    "test_coll.insert_many([\n",
    "    {\"county\": \"LA\", \"spend\": 1000, \"year\": 2023},\n",
    "    {\"county\": \"NY\", \"spend\": 2000, \"year\": 2023},\n",
    "    {\"county\": \"LA\", \"spend\": 1500, \"year\": 2024},\n",
    "    {\"county\": \"NY\", \"spend\": 2500, \"year\": 2024},\n",
    "])\n",
    "\n",
    "print(\"Original collection:\")\n",
    "for doc in test_coll:\n",
    "    print(f\"  {doc}\")\n",
    "\n",
    "# Test filtering\n",
    "print(\"\\n1. Filtering (spend > 1500):\")\n",
    "filtered = filter_collection(test_coll, lambda doc: doc.get(\"spend\", 0) > 1500)\n",
    "for doc in filtered:\n",
    "    print(f\"  {doc}\")\n",
    "\n",
    "# Test projection\n",
    "print(\"\\n2. Projection (county, spend):\")\n",
    "projected = project_collection(test_coll, [\"county\", \"spend\"])\n",
    "for doc in projected:\n",
    "    print(f\"  {doc}\")\n",
    "\n",
    "# Test group by\n",
    "print(\"\\n3. Group by county:\")\n",
    "groups = group_by(test_coll, \"county\")\n",
    "for key, docs in groups.items():\n",
    "    print(f\"  {key}: {len(docs)} documents\")\n",
    "\n",
    "# Test aggregation\n",
    "print(\"\\n4. Aggregation (sum of spend by county):\")\n",
    "agg_result = aggregate(test_coll, \"county\", \"spend\", \"sum\")\n",
    "for result in agg_result:\n",
    "    print(f\"  {result}\")\n",
    "\n",
    "# Test join\n",
    "print(\"\\n5. Join:\")\n",
    "coll1 = Collection(\"coll1\")\n",
    "coll1.insert_many([\n",
    "    {\"county\": \"LA\", \"population\": 10000000},\n",
    "    {\"county\": \"NY\", \"population\": 8000000},\n",
    "])\n",
    "\n",
    "coll2 = Collection(\"coll2\")\n",
    "coll2.insert_many([\n",
    "    {\"county_code\": \"LA\", \"unemployment\": 5.2},\n",
    "    {\"county_code\": \"NY\", \"unemployment\": 4.8},\n",
    "])\n",
    "\n",
    "joined = join_collections(coll1, coll2, \"county\", \"county_code\")\n",
    "for doc in joined:\n",
    "    print(f\"  {doc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: JSON File Loading\n",
    "\n",
    "Function to load JSON files (arrays of objects) into collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing File Loading:\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Function to load JSON file into a collection\n",
    "def load_json_file(filename):\n",
    "    \"\"\"\n",
    "    Load a JSON file (array of objects) into a Collection\n",
    "    \n",
    "    Args:\n",
    "        filename: Path to JSON file\n",
    "    \n",
    "    Returns:\n",
    "        Collection object\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            content = f.read().strip()\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json_load(content)\n",
    "        \n",
    "        # Create collection (handle both Windows and Unix paths)\n",
    "        collection_name = filename.replace('\\\\', '/').split('/')[-1].split('.')[0]\n",
    "        collection = Collection(collection_name)\n",
    "        \n",
    "        # Handle both array of objects and single object\n",
    "        if isinstance(data, list):\n",
    "            for doc in data:\n",
    "                if isinstance(doc, dict):\n",
    "                    collection.insert(doc)\n",
    "        elif isinstance(data, dict):\n",
    "            collection.insert(data)\n",
    "        else:\n",
    "            raise ValueError(\"JSON file must contain an object or array of objects\")\n",
    "        \n",
    "        return collection\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filename} not found. Creating empty collection.\")\n",
    "        collection_name = filename.replace('\\\\', '/').split('/')[-1].split('.')[0]\n",
    "        return Collection(collection_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filename}: {e}\")\n",
    "        collection_name = filename.replace('\\\\', '/').split('/')[-1].split('.')[0]\n",
    "        return Collection(collection_name)\n",
    "\n",
    "# Function to parse CSV file into a collection\n",
    "def parse_csv_line(line):\n",
    "    \"\"\"Parse a single CSV line, handling quoted fields\"\"\"\n",
    "    fields = []\n",
    "    current_field = \"\"\n",
    "    in_quotes = False\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(line):\n",
    "        char = line[i]\n",
    "        \n",
    "        if char == '\"':\n",
    "            if in_quotes and i + 1 < len(line) and line[i + 1] == '\"':\n",
    "                # Escaped quote\n",
    "                current_field += '\"'\n",
    "                i += 2\n",
    "            else:\n",
    "                # Toggle quote state\n",
    "                in_quotes = not in_quotes\n",
    "                i += 1\n",
    "        elif char == ',' and not in_quotes:\n",
    "            # End of field\n",
    "            fields.append(current_field)\n",
    "            current_field = \"\"\n",
    "            i += 1\n",
    "        else:\n",
    "            current_field += char\n",
    "            i += 1\n",
    "    \n",
    "    # Add last field\n",
    "    fields.append(current_field)\n",
    "    return fields\n",
    "\n",
    "def load_csv_file(filename):\n",
    "    \"\"\"\n",
    "    Load a CSV file into a Collection\n",
    "    \n",
    "    Args:\n",
    "        filename: Path to CSV file\n",
    "    \n",
    "    Returns:\n",
    "        Collection object\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        if len(lines) == 0:\n",
    "            raise ValueError(\"CSV file is empty\")\n",
    "        \n",
    "        # Parse header\n",
    "        header = parse_csv_line(lines[0].strip())\n",
    "        \n",
    "        # Create collection\n",
    "        collection_name = filename.replace('\\\\', '/').split('/')[-1].split('.')[0]\n",
    "        collection = Collection(collection_name)\n",
    "        \n",
    "        # Parse data rows\n",
    "        for line in lines[1:]:\n",
    "            line = line.strip()\n",
    "            if not line:  # Skip empty lines\n",
    "                continue\n",
    "            \n",
    "            fields = parse_csv_line(line)\n",
    "            if len(fields) != len(header):\n",
    "                # Skip malformed rows\n",
    "                continue\n",
    "            \n",
    "            # Create document\n",
    "            doc = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                # Try to convert to number if possible\n",
    "                field = field.strip()\n",
    "                if field == '' or field == 'N/A' or field == '-9999' or field == '-8888':\n",
    "                    doc[header[i]] = None\n",
    "                else:\n",
    "                    try:\n",
    "                        # Try integer first\n",
    "                        if '.' in field:\n",
    "                            doc[header[i]] = float(field)\n",
    "                        else:\n",
    "                            doc[header[i]] = int(field)\n",
    "                    except ValueError:\n",
    "                        # Keep as string\n",
    "                        doc[header[i]] = field\n",
    "            \n",
    "            collection.insert(doc)\n",
    "        \n",
    "        return collection\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filename} not found. Creating empty collection.\")\n",
    "        collection_name = filename.replace('\\\\', '/').split('/')[-1].split('.')[0]\n",
    "        return Collection(collection_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filename}: {e}\")\n",
    "        collection_name = filename.replace('\\\\', '/').split('/')[-1].split('.')[0]\n",
    "        return Collection(collection_name)\n",
    "\n",
    "# Function to load Excel file into a collection\n",
    "def load_excel_file(filename, sheet_name=None, header_row=None):\n",
    "    \"\"\"\n",
    "    Load an Excel file into a Collection using openpyxl\n",
    "    \n",
    "    Args:\n",
    "        filename: Path to Excel file\n",
    "        sheet_name: Name of sheet to load (None for first sheet)\n",
    "        header_row: Row number containing headers (0-indexed). If None, auto-detects the first non-empty row.\n",
    "    \n",
    "    Returns:\n",
    "        Collection object\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to import openpyxl\n",
    "        try:\n",
    "            from openpyxl import load_workbook\n",
    "        except ImportError:\n",
    "            print(\"Warning: openpyxl not available. Install with: pip install openpyxl\")\n",
    "            print(f\"Creating empty collection for {filename}\")\n",
    "            collection_name = filename.replace('\\\\', '/').split('/')[-1].split('.')[0]\n",
    "            return Collection(collection_name)\n",
    "        \n",
    "        # Load workbook\n",
    "        wb = load_workbook(filename, data_only=True)\n",
    "        \n",
    "        # Get sheet\n",
    "        if sheet_name:\n",
    "            ws = wb[sheet_name]\n",
    "        else:\n",
    "            ws = wb.active\n",
    "        \n",
    "        # Determine header row (auto-detect if not provided)\n",
    "        headers = None\n",
    "        current_row_index = -1\n",
    "        \n",
    "        def row_has_data(row):\n",
    "            return any(cell is not None and str(cell).strip() != \"\" for cell in row)\n",
    "        \n",
    "        # Create collection\n",
    "        collection_name = filename.replace('\\\\', '/').split('/')[-1].split('.')[0]\n",
    "        collection = Collection(collection_name)\n",
    "        \n",
    "        # Parse rows\n",
    "        for row in ws.iter_rows(values_only=True):\n",
    "            current_row_index += 1\n",
    "            \n",
    "            # Skip rows before the specified header_row\n",
    "            if header_row is not None and current_row_index < header_row:\n",
    "                continue\n",
    "            \n",
    "            if headers is None:\n",
    "                if header_row is None and not row_has_data(row):\n",
    "                    continue  # still searching for header row\n",
    "                headers = [str(cell).strip() if cell is not None else \"\" for cell in row]\n",
    "                continue  # move to next row for data\n",
    "            \n",
    "            # Skip empty rows\n",
    "            if all(cell is None or (isinstance(cell, str) and cell.strip() == '') for cell in row):\n",
    "                continue\n",
    "            \n",
    "            # Create document\n",
    "            doc = {}\n",
    "            for i, cell_value in enumerate(row):\n",
    "                if i >= len(headers):\n",
    "                    continue\n",
    "                field_name = headers[i].strip()\n",
    "                if not field_name:\n",
    "                    continue\n",
    "                \n",
    "                # Convert cell value\n",
    "                if cell_value is None or cell_value == '':\n",
    "                    doc[field_name] = None\n",
    "                elif isinstance(cell_value, (int, float)):\n",
    "                    doc[field_name] = cell_value\n",
    "                else:\n",
    "                    # Try to convert string to number\n",
    "                    cell_str = str(cell_value).strip()\n",
    "                    if cell_str == '' or cell_str == 'N/A' or cell_str == '-9999' or cell_str == '-8888':\n",
    "                        doc[field_name] = None\n",
    "                    else:\n",
    "                        try:\n",
    "                            if '.' in cell_str:\n",
    "                                doc[field_name] = float(cell_str)\n",
    "                            else:\n",
    "                                doc[field_name] = int(cell_str)\n",
    "                        except ValueError:\n",
    "                            doc[field_name] = cell_str\n",
    "            \n",
    "            if doc:  # Only insert non-empty documents\n",
    "                collection.insert(doc)\n",
    "        \n",
    "        return collection\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filename} not found. Creating empty collection.\")\n",
    "        collection_name = filename.replace('\\\\', '/').split('/')[-1].split('.')[0]\n",
    "        return Collection(collection_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filename}: {e}\")\n",
    "        collection_name = filename.replace('\\\\', '/').split('/')[-1].split('.')[0]\n",
    "        return Collection(collection_name)\n",
    "\n",
    "# Test file loading\n",
    "print(\"Testing File Loading:\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Sample Data Generation\n",
    "\n",
    "Creating sample datasets for Green Purchasing Behavior analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3491599650.py, line 233)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[17], line 233\u001b[1;36m\u001b[0m\n\u001b[1;33m    +\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Transform Food Environment Atlas data for Green Purchasing Behavior analysis\n",
    "\n",
    "def transform_food_data(food_data_collection):\n",
    "    \"\"\"\n",
    "    Transform Food Environment Atlas data into format suitable for green purchasing analysis.\n",
    "    Focus on variables related to local foods, farmers markets, and direct sales.\n",
    "    \n",
    "    Args:\n",
    "        food_data_collection: Collection with Food Environment Atlas data\n",
    "    \n",
    "    Returns:\n",
    "        Collection with transformed data focused on green purchasing indicators\n",
    "    \"\"\"\n",
    "    transformed = Collection(\"food_spending\")\n",
    "    \n",
    "    # Variables related to green/sustainable purchasing behavior\n",
    "    green_variables = [\n",
    "        'DIRSALES17',  # Direct farm sales, 2017\n",
    "        'DIRSALES12',  # Direct farm sales, 2012\n",
    "        'FMRKT18',     # Farmers' markets, 2018\n",
    "        'FMRKT13',     # Farmers' markets, 2013\n",
    "        'VEG_ACRES17', # Vegetable acres harvested, 2017\n",
    "        'VEG_ACRES12', # Vegetable acres harvested, 2012\n",
    "        'FRESHVEG_ACRES17',  # Fresh vegetable acres, 2017\n",
    "        'FRESHVEG_ACRES12',  # Fresh vegetable acres, 2012\n",
    "        'GROC20',      # Grocery stores, 2020\n",
    "        'GROC16',      # Grocery stores, 2016\n",
    "        'SPECS20',     # Specialized food stores, 2020\n",
    "        'SPECS16',     # Specialized food stores, 2016\n",
    "    ]\n",
    "    \n",
    "    # Group data by county and variable\n",
    "    county_vars = {}\n",
    "    for doc in food_data_collection:\n",
    "        county = doc.get('County')\n",
    "        var_code = doc.get('Variable_Code')\n",
    "        value = doc.get('Value')\n",
    "        \n",
    "        if county and var_code and var_code in green_variables and value is not None:\n",
    "            if county not in county_vars:\n",
    "                county_vars[county] = {}\n",
    "            county_vars[county][var_code] = value\n",
    "    \n",
    "    # Create transformed documents\n",
    "    for county, vars_dict in county_vars.items():\n",
    "        # Create documents for different categories\n",
    "        if 'DIRSALES17' in vars_dict:\n",
    "            # Direct sales as proxy for local/organic food spending\n",
    "            transformed.insert({\n",
    "                \"county\": county,\n",
    "                \"category\": \"direct_sales\",\n",
    "                \"spend\": vars_dict.get('DIRSALES17', 0) * 1000,  # Convert from thousands\n",
    "                \"year\": 2017\n",
    "            })\n",
    "        \n",
    "        if 'FMRKT18' in vars_dict:\n",
    "            # Farmers markets as indicator of green purchasing\n",
    "            transformed.insert({\n",
    "                \"county\": county,\n",
    "                \"category\": \"farmers_markets\",\n",
    "                \"spend\": vars_dict.get('FMRKT18', 0) * 100,  # Scale for analysis\n",
    "                \"year\": 2018\n",
    "            })\n",
    "        \n",
    "        if 'FRESHVEG_ACRES17' in vars_dict:\n",
    "            # Fresh vegetable production as green indicator\n",
    "            transformed.insert({\n",
    "                \"county\": county,\n",
    "                \"category\": \"fresh_vegetables\",\n",
    "                \"spend\": vars_dict.get('FRESHVEG_ACRES17', 0) * 10,  # Scale for analysis\n",
    "                \"year\": 2017\n",
    "            })\n",
    "        \n",
    "        if 'SPECS20' in vars_dict:\n",
    "            # Specialized food stores (often organic/natural)\n",
    "            transformed.insert({\n",
    "                \"county\": county,\n",
    "                \"category\": \"specialized_stores\",\n",
    "                \"spend\": vars_dict.get('SPECS20', 0) * 50,  # Scale for analysis\n",
    "                \"year\": 2020\n",
    "            })\n",
    "    \n",
    "    return transformed\n",
    "\n",
    "def transform_socioeconomic_data(food_data_collection):\n",
    "    \"\"\"\n",
    "    Extract socioeconomic data (income, poverty) from Food Environment Atlas\n",
    "    \n",
    "    Args:\n",
    "        food_data_collection: Collection with Food Environment Atlas data\n",
    "    \n",
    "    Returns:\n",
    "        Collection with socioeconomic data\n",
    "    \"\"\"\n",
    "    jobs = Collection(\"jobs\")\n",
    "    \n",
    "    # Variables for income/jobs\n",
    "    income_vars = ['MEDHHINC21']  # Median household income, 2021\n",
    "    \n",
    "    county_income = {}\n",
    "    for doc in food_data_collection:\n",
    "        county = doc.get('County')\n",
    "        var_code = doc.get('Variable_Code')\n",
    "        value = doc.get('Value')\n",
    "        \n",
    "        if county and var_code == 'MEDHHINC21' and value is not None:\n",
    "            county_income[county] = value\n",
    "    \n",
    "    # Create job/income documents\n",
    "    for county, income in county_income.items():\n",
    "        jobs.insert({\n",
    "            \"county\": county,\n",
    "            \"occupation\": \"general\",\n",
    "            \"median_income\": int(income) if income else None,\n",
    "            \"year\": 2021\n",
    "        })\n",
    "    \n",
    "    return jobs\n",
    "\n",
    "def transform_unemployment_data(food_data_collection):\n",
    "    \"\"\"\n",
    "    Extract unemployment/poverty data from Food Environment Atlas\n",
    "    \n",
    "    Args:\n",
    "        food_data_collection: Collection with Food Environment Atlas data\n",
    "    \n",
    "    Returns:\n",
    "        Collection with unemployment/poverty data\n",
    "    \"\"\"\n",
    "    unemployment = Collection(\"unemployment\")\n",
    "    \n",
    "    # Variables for economic indicators\n",
    "    poverty_vars = ['POVRATE21']  # Poverty rate, 2021\n",
    "    \n",
    "    county_poverty = {}\n",
    "    for doc in food_data_collection:\n",
    "        county = doc.get('County')\n",
    "        var_code = doc.get('Variable_Code')\n",
    "        value = doc.get('Value')\n",
    "        \n",
    "        if county and var_code == 'POVRATE21' and value is not None:\n",
    "            county_poverty[county] = value\n",
    "    \n",
    "    # Create unemployment documents (using poverty rate as proxy)\n",
    "    for county, poverty_rate in county_poverty.items():\n",
    "        unemployment.insert({\n",
    "            \"county\": county,\n",
    "            \"rate\": float(poverty_rate) if poverty_rate else None,\n",
    "            \"year\": 2021\n",
    "        })\n",
    "    \n",
    "    return unemployment\n",
    "\n",
    "def transform_employment_data(food_data_collection):\n",
    "    \"\"\"\n",
    "    Extract and transform employment-related data from Food Environment Atlas.\n",
    "    Since the Atlas doesn't have direct employment data, we use income and economic indicators\n",
    "    as proxies for employment levels.\n",
    "    \n",
    "    Args:\n",
    "        food_data_collection: Collection with Food Environment Atlas data\n",
    "    \n",
    "    Returns:\n",
    "        Collection with employment data\n",
    "    \"\"\"\n",
    "    employment = Collection(\"employment\")\n",
    "    \n",
    "    # Extract income and poverty data to create employment indicators\n",
    "    county_data = {}\n",
    "    for doc in food_data_collection:\n",
    "        county = doc.get('County')\n",
    "        var_code = doc.get('Variable_Code')\n",
    "        value = doc.get('Value')\n",
    "        \n",
    "        if county and value is not None:\n",
    "            if county not in county_data:\n",
    "                county_data[county] = {}\n",
    "            \n",
    "            if var_code == 'MEDHHINC21':\n",
    "                county_data[county]['median_income'] = value\n",
    "            elif var_code == 'POVRATE21':\n",
    "                county_data[county]['poverty_rate'] = value\n",
    "            elif var_code == 'METRO23':\n",
    "                county_data[county]['metro'] = value\n",
    "    \n",
    "    # Create employment documents with employment categories based on income\n",
    "    for county, data in county_data.items():\n",
    "        median_income = data.get('median_income')\n",
    "        poverty_rate = data.get('poverty_rate')\n",
    "        metro = data.get('metro', 'Nonmetro')\n",
    "        \n",
    "        if median_income is not None:\n",
    "            # Categorize employment level based on income\n",
    "            # Higher income typically correlates with better employment opportunities\n",
    "            if median_income >= 75000:\n",
    "                employment_level = \"high\"\n",
    "                occupation = \"professional\"\n",
    "            elif median_income >= 50000:\n",
    "                employment_level = \"medium_high\"\n",
    "                occupation = \"skilled\"\n",
    "            elif median_income >= 35000:\n",
    "                employment_level = \"medium\"\n",
    "                occupation = \"service\"\n",
    "            else:\n",
    "                employment_level = \"low\"\n",
    "                occupation = \"retail\"\n",
    "            \n",
    "            # Calculate employment rate proxy (100 - poverty rate, adjusted)\n",
    "            # This is a simplified proxy since we don't have actual employment data\n",
    "            if poverty_rate is not None:\n",
    "                # Employment rate proxy: lower poverty = higher employment\n",
    "                employment_rate = max(0, min(100, 100 - poverty_rate * 1.5))\n",
    "            else:\n",
    "                # Estimate based on income if poverty rate not available\n",
    "                employment_rate = min(95, max(60, (median_income / 1000) * 0.8))\n",
    "            \n",
    "            employment.insert({\n",
    "                \"county\": county,\n",
    "                \"occupation\": occupation,\n",
    "                \"median_income\": int(median_income) if median_income else None,\n",
    "                \"employment_level\": employment_level,\n",
    "                \"employment_rate\": round(employment_rate, 2),\n",
    "                \"poverty_rate\": float(poverty_rate) if poverty_rate else None,\n",
    "                \"metro_status\": metro,\n",
    "                \"year\": 2021\n",
    "            })\n",
    "    \n",
    "    return employment\n",
    "\n",
    "print(\"Data transformation functions created for Food Environment Atlas data\")\n",
    "\n",
    "# Transform Excel data files for Green Purchasing Behavior analysis\n",
    "\n",
    "# Helper utilities for Excel -> Collection transformations\n",
    "def get_field_value(doc, keywords):\n",
    "    for key, value in doc.items():\n",
    "        if key is None:\n",
    "            continue\n",
    "        key_lower = str(key).strip().lower()\n",
    "        for keyword in keywords:\n",
    "            if keyword in key_lower:\n",
    "                if isinstance(value, str):\n",
    "                    return value.strip()\n",
    "                return value\n",
    "    return None\n",
    "\n",
    "def to_float(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "    if isinstance(value, (int, float)):\n",
    "        return float(value)\n",
    "    value_str = str(value).strip()\n",
    "    if value_str == \"\":\n",
    "        return None\n",
    "    value_str = value_str.replace(',', '')\n",
    "    if value_str.endswith('%'):\n",
    "        value_str = value_str[:-1]\n",
    "    try:\n",
    "        return float(value_str)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def to_int(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "    if isinstance(value, (int, float)):\n",
    "        return int(value)\n",
    "    value_str = str(value).strip()\n",
    "    if value_str == \"\":\n",
    "        return None\n",
    "    value_str = value_str.replace(',', '')\n",
    "    match = re.search(r'-?\\d+', value_str)\n",
    "    if match:\n",
    "        try:\n",
    "            return int(match.group(0))\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def infer_year(value, default_year):\n",
    "    if value is None:\n",
    "        return default_year\n",
    "    if isinstance(value, (int, float)):\n",
    "        year = int(value)\n",
    "        if 1900 <= year <= 2100:\n",
    "            return year\n",
    "    value_str = str(value)\n",
    "    match = re.search(r'(19|20)\\d{2}', value_str)\n",
    "    if match:\n",
    "        return int(match.group(0))\n",
    "    return default_year\n",
    "\n",
    "def transform_consumer_data(consumer_collection):\n",
    "    \"\"\"\n",
    "    Transform consumer spending data from Excel into food spending format\n",
    "    \"\"\"\n",
    "    food_spending = Collection(\"food_spending\")\n",
    "    county_keywords = ['county', 'area', 'region', 'location', 'metro', 'city', 'borough']\n",
    "    category_keywords = ['category', 'item', 'product', 'series', 'description', 'class']\n",
    "    spend_keywords = ['spend', 'expenditure', 'value', 'amount', 'dollar', 'sales', 'cost', 'price']\n",
    "    year_keywords = ['year', 'date', 'period', 'month', 'time']\n",
    "    \n",
    "    for doc in consumer_collection:\n",
    "        county = get_field_value(doc, county_keywords)\n",
    "        spend = to_float(get_field_value(doc, spend_keywords))\n",
    "        if not county or spend is None:\n",
    "            continue\n",
    "        category = get_field_value(doc, category_keywords) or \"general\"\n",
    "        year = infer_year(get_field_value(doc, year_keywords), 2023)\n",
    "        \n",
    "        food_spending.insert({\n",
    "            \"county\": str(county),\n",
    "            \"category\": str(category).strip().lower().replace(' ', '_'),\n",
    "            \"spend\": spend,\n",
    "            \"year\": year\n",
    "        })\n",
    "    \n",
    "    return food_spending\n",
    "\n",
    "def transform_employment_excel_data(employment_collection):\n",
    "    \"\"\"\n",
    "    Transform employment data from Excel into jobs/employment format\n",
    "    \"\"\"\n",
    "    jobs = Collection(\"jobs\")\n",
    "    county_keywords = ['county', 'area', 'region', 'location', 'metro', 'city', 'borough']\n",
    "    income_keywords = ['median_income', 'income', 'wage', 'salary', 'earnings', 'pay']\n",
    "    occupation_keywords = ['occupation', 'job', 'title', 'category', 'sector', 'industry', 'class']\n",
    "    year_keywords = ['year', 'date', 'period', 'month']\n",
    "    \n",
    "    for doc in employment_collection:\n",
    "        county = get_field_value(doc, county_keywords)\n",
    "        if not county:\n",
    "            continue\n",
    "        median_income = to_int(get_field_value(doc, income_keywords))\n",
    "        occupation = get_field_value(doc, occupation_keywords) or \"general\"\n",
    "        year = infer_year(get_field_value(doc, year_keywords), 2024)\n",
    "        \n",
    "        jobs.insert({\n",
    "            \"county\": str(county),\n",
    "            \"occupation\": str(occupation).strip().lower().replace(' ', '_'),\n",
    "            \"median_income\": median_income,\n",
    "            \"year\": year\n",
    "        })\n",
    "    \n",
    "    return jobs\n",
    "\n",
    "def transform_unemployment_excel_data(unemployment_collection):\n",
    "    \"\"\"\n",
    "    Transform unemployment data from Excel into unemployment format\n",
    "    \"\"\"\n",
    "    unemployment = Collection(\"unemployment\")\n",
    "    county_keywords = ['county', 'area', 'region', 'location', 'metro', 'city', 'borough']\n",
    "    rate_keywords = ['unemployment', 'jobless', 'rate', 'percent', 'pct', 'labor', 'employment_rate']\n",
    "    year_keywords = ['year', 'date', 'period', 'month']\n",
    "    \n",
    "    for doc in unemployment_collection:\n",
    "        county = get_field_value(doc, county_keywords)\n",
    "        rate = to_float(get_field_value(doc, rate_keywords))\n",
    "        if not county or rate is None:\n",
    "            continue\n",
    "        year = infer_year(get_field_value(doc, year_keywords), 2024)\n",
    "        \n",
    "        unemployment.insert({\n",
    "            \"county\": str(county),\n",
    "            \"rate\": rate,\n",
    "            \"year\": year\n",
    "        })\n",
    "    \n",
    "    return unemployment\n",
    "\n",
    "print(\"Excel data transformation functions created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Green Purchasing Behavior Application\n",
    "\n",
    "Application that uses all implemented functions to analyze sustainable food purchasing behavior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GREEN PURCHASING BEHAVIOR ANALYSIS APPLICATION\n",
      "======================================================================\n",
      "\n",
      "1. Loading Data from Excel Files:\n",
      "----------------------------------------------------------------------\n",
      "Loading consumer spending data...\n",
      "Loaded 4460 records from consumer data\n",
      "Loading employment data...\n",
      "Loaded 414437 records from employment data\n",
      "Loading unemployment data...\n",
      "Loaded 392 records from unemployment data\n",
      "\n",
      "Loading Food Environment Atlas data (supplementary)...\n",
      "Loaded 957753 records from Food Environment Atlas\n",
      "\n",
      "2. Transforming Data for Green Purchasing Analysis:\n",
      "----------------------------------------------------------------------\n",
      "Transformed to 0 food spending records from consumer data\n",
      "Transformed to 414437 job/employment records from employment data\n",
      "Transformed to 0 unemployment records from unemployment data\n",
      "Transformed to 1833 employment records from Food Environment Atlas\n",
      "\n",
      "3. Question 1: Who is buying sustainable food? (Geography Analysis)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "2a. Filtering: Counties with spending > $1000\n",
      "Found 0 records with spending > $1000\n",
      "\n",
      "2b. Projection: County and spending amounts\n",
      "\n",
      "2c. Group By: Spending by county\n",
      "\n",
      "2d. Aggregation: Total spending by county\n",
      "\n",
      "4. Question 2: How income influences sustainable purchasing behavior\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "4a. Join: Food spending with jobs data (on county)\n",
      "Joined collection has 0 records\n",
      "\n",
      "4a2. Join: Food spending with employment data (on county)\n",
      "Joined collection has 0 records\n",
      "\n",
      "4b. Filtering: High income areas (median_income > $40,000)\n",
      "Found 0 records in high-income areas\n",
      "\n",
      "4b2. Filtering: High employment areas (employment_rate > 85%)\n",
      "Found 0 records in high-employment areas\n",
      "\n",
      "4c. Aggregation: Average spending by income level\n",
      "Average spending by income category:\n",
      "\n",
      "4c2. Aggregation: Average spending by employment level\n",
      "Average spending by employment level:\n",
      "\n",
      "4c3. Aggregation: Average spending by occupation type\n",
      "Average spending by occupation type:\n",
      "\n",
      "4c4. Aggregation: Average spending by metro/nonmetro status\n",
      "Average spending by metro status:\n",
      "\n",
      "5. Question 3: Do economic shocks (poverty) change spending habits?\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "4a. Join: Food spending with unemployment data\n",
      "Joined collection has 0 records\n",
      "\n",
      "5b. Filtering: High poverty areas (rate > 15%)\n",
      "Found 0 records in high-poverty areas\n",
      "\n",
      "5c. Aggregation: Spending comparison by poverty level\n",
      "Average spending by poverty category:\n",
      "\n",
      "5d. Spending by year and poverty rate\n",
      "\n",
      "6. Question 4: How does employment status affect green purchasing behavior?\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "6a. Join: Employment data with food spending\n",
      "Joined collection has 0 records\n",
      "\n",
      "6b. Filtering: Counties with employment rate > 90%\n",
      "Found 0 records in high-employment areas\n",
      "\n",
      "6c. Aggregation: Spending by employment rate ranges\n",
      "Average spending by employment rate category:\n",
      "\n",
      "6d. Complex Analysis: Employment level by food category\n",
      "Top combinations of employment level and food category:\n",
      "\n",
      "7. Question 5: Spending patterns by food category\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "7a. Aggregation: Total spending by category\n",
      "\n",
      "7b. Aggregation: Average spending by category\n",
      "\n",
      "7c. Complex Query: Category spending by county (using group by and aggregation)\n",
      "Top spending combinations:\n",
      "\n",
      "======================================================================\n",
      "APPLICATION ANALYSIS COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Green Purchasing Behavior Analysis Application\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"GREEN PURCHASING BEHAVIOR ANALYSIS APPLICATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load data from Excel files\n",
    "print(\"\\n1. Loading Data from Excel Files:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Load consumer spending data\n",
    "print(\"Loading consumer spending data...\")\n",
    "consumer_data_raw = load_excel_file('consumer-data/cu-all-detail-2023.xlsx')\n",
    "print(f\"Loaded {len(consumer_data_raw)} records from consumer data\")\n",
    "\n",
    "# Load employment data\n",
    "print(\"Loading employment data...\")\n",
    "employment_data_raw = load_excel_file('employement_data/all_data_M_2024.xlsx')\n",
    "print(f\"Loaded {len(employment_data_raw)} records from employment data\")\n",
    "\n",
    "# Load unemployment data\n",
    "print(\"Loading unemployment data...\")\n",
    "unemployment_data_raw = load_excel_file('unemployment-rate-data/metro-annual-unemployment-rates.xlsx')\n",
    "print(f\"Loaded {len(unemployment_data_raw)} records from unemployment data\")\n",
    "\n",
    "# Load Food Environment Atlas data (for supplementary analysis)\n",
    "print(\"\\nLoading Food Environment Atlas data (supplementary)...\")\n",
    "food_data_raw = load_csv_file('food_data/StateAndCountyData.csv')\n",
    "print(f\"Loaded {len(food_data_raw)} records from Food Environment Atlas\")\n",
    "\n",
    "# Transform Excel data for analysis\n",
    "print(\"\\n2. Transforming Data for Green Purchasing Analysis:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Transform consumer data to food spending format\n",
    "food_spending = transform_consumer_data(consumer_data_raw)\n",
    "print(f\"Transformed to {len(food_spending)} food spending records from consumer data\")\n",
    "\n",
    "# Transform employment data\n",
    "jobs = transform_employment_excel_data(employment_data_raw)\n",
    "print(f\"Transformed to {len(jobs)} job/employment records from employment data\")\n",
    "\n",
    "# Transform unemployment data\n",
    "unemployment = transform_unemployment_excel_data(unemployment_data_raw)\n",
    "print(f\"Transformed to {len(unemployment)} unemployment records from unemployment data\")\n",
    "\n",
    "# Also create employment data from Food Environment Atlas (for additional insights)\n",
    "employment = transform_employment_data(food_data_raw)\n",
    "print(f\"Transformed to {len(employment)} employment records from Food Environment Atlas\")\n",
    "\n",
    "# Application Question 1: Who is buying sustainable food? (Demographics, Geography)\n",
    "print(\"\\n3. Question 1: Who is buying sustainable food? (Geography Analysis)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Filter: High spending counties (spend > 1000)\n",
    "print(\"\\n2a. Filtering: Counties with spending > $1000\")\n",
    "high_spending = filter_collection(food_spending, lambda doc: doc.get(\"spend\", 0) > 1000)\n",
    "print(f\"Found {len(high_spending)} records with spending > $1000\")\n",
    "\n",
    "# Projection: County and spend\n",
    "print(\"\\n2b. Projection: County and spending amounts\")\n",
    "county_spending = project_collection(high_spending, [\"county\", \"spend\"])\n",
    "for doc in county_spending:\n",
    "    print(f\"  {doc['county']}: ${doc['spend']:.2f}\")\n",
    "\n",
    "# Group by: County\n",
    "print(\"\\n2c. Group By: Spending by county\")\n",
    "county_groups = group_by(food_spending, \"county\")\n",
    "for county, docs in county_groups.items():\n",
    "    total = sum(doc.get(\"spend\", 0) for doc in docs)\n",
    "    print(f\"  {county}: ${total:.2f} total spending ({len(docs)} records)\")\n",
    "\n",
    "# Aggregation: Total spending by county\n",
    "print(\"\\n2d. Aggregation: Total spending by county\")\n",
    "total_by_county = aggregate(food_spending, \"county\", \"spend\", \"sum\")\n",
    "for result in total_by_county:\n",
    "    print(f\"  {result['county']}: ${result['sum(spend)']:.2f}\")\n",
    "\n",
    "# Application Question 2: How income influences sustainable purchasing\n",
    "print(\"\\n4. Question 2: How income influences sustainable purchasing behavior\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Join: Food spending with jobs data\n",
    "print(\"\\n4a. Join: Food spending with jobs data (on county)\")\n",
    "spending_jobs = join_collections(food_spending, jobs, \"county\", \"county\")\n",
    "print(f\"Joined collection has {len(spending_jobs)} records\")\n",
    "\n",
    "# Join: Food spending with employment data\n",
    "print(\"\\n4a2. Join: Food spending with employment data (on county)\")\n",
    "spending_employment = join_collections(food_spending, employment, \"county\", \"county\")\n",
    "print(f\"Joined collection has {len(spending_employment)} records\")\n",
    "\n",
    "# Filter: High income areas (median_income > 40000)\n",
    "print(\"\\n4b. Filtering: High income areas (median_income > $40,000)\")\n",
    "high_income_spending = filter_collection(spending_jobs, \n",
    "                                        lambda doc: doc.get(\"median_income\", 0) > 40000)\n",
    "print(f\"Found {len(high_income_spending)} records in high-income areas\")\n",
    "\n",
    "# Filter: High employment areas\n",
    "print(\"\\n4b2. Filtering: High employment areas (employment_rate > 85%)\")\n",
    "high_employment_spending = filter_collection(spending_employment, \n",
    "                                            lambda doc: doc.get(\"employment_rate\", 0) > 85.0)\n",
    "print(f\"Found {len(high_employment_spending)} records in high-employment areas\")\n",
    "\n",
    "# Aggregation: Average spending by income level\n",
    "print(\"\\n4c. Aggregation: Average spending by income level\")\n",
    "# First, categorize income levels\n",
    "def categorize_income(doc):\n",
    "    income = doc.get(\"median_income\", 0)\n",
    "    if income >= 45000:\n",
    "        return \"high\"\n",
    "    elif income >= 40000:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"low\"\n",
    "\n",
    "# Add income category to documents\n",
    "spending_with_category = Collection(\"spending_categorized\")\n",
    "for doc in spending_jobs:\n",
    "    new_doc = doc.copy()\n",
    "    new_doc[\"income_category\"] = categorize_income(doc)\n",
    "    spending_with_category.insert(new_doc)\n",
    "\n",
    "avg_by_income = aggregate(spending_with_category, \"income_category\", \"spend\", \"avg\")\n",
    "print(\"Average spending by income category:\")\n",
    "for result in avg_by_income:\n",
    "    print(f\"  {result['income_category']}: ${result['avg(spend)']:.2f}\")\n",
    "\n",
    "# Aggregation: Average spending by employment level\n",
    "print(\"\\n4c2. Aggregation: Average spending by employment level\")\n",
    "avg_by_employment = aggregate(spending_employment, \"employment_level\", \"spend\", \"avg\")\n",
    "print(\"Average spending by employment level:\")\n",
    "for result in avg_by_employment:\n",
    "    print(f\"  {result['employment_level']}: ${result['avg(spend)']:.2f}\")\n",
    "\n",
    "# Aggregation: Average spending by occupation type\n",
    "print(\"\\n4c3. Aggregation: Average spending by occupation type\")\n",
    "avg_by_occupation = aggregate(spending_employment, \"occupation\", \"spend\", \"avg\")\n",
    "print(\"Average spending by occupation type:\")\n",
    "for result in avg_by_occupation:\n",
    "    print(f\"  {result['occupation']}: ${result['avg(spend)']:.2f}\")\n",
    "\n",
    "# Aggregation: Average spending by metro status\n",
    "print(\"\\n4c4. Aggregation: Average spending by metro/nonmetro status\")\n",
    "avg_by_metro = aggregate(spending_employment, \"metro_status\", \"spend\", \"avg\")\n",
    "print(\"Average spending by metro status:\")\n",
    "for result in avg_by_metro:\n",
    "    print(f\"  {result['metro_status']}: ${result['avg(spend)']:.2f}\")\n",
    "\n",
    "# Application Question 3: Economic shocks and spending habits\n",
    "print(\"\\n5. Question 3: Do economic shocks (poverty) change spending habits?\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Join: Food spending with unemployment data\n",
    "print(\"\\n4a. Join: Food spending with unemployment data\")\n",
    "spending_unemployment = join_collections(food_spending, unemployment, \"county\", \"county\")\n",
    "print(f\"Joined collection has {len(spending_unemployment)} records\")\n",
    "\n",
    "# Filter: High poverty areas (rate > 15%)\n",
    "print(\"\\n5b. Filtering: High poverty areas (rate > 15%)\")\n",
    "high_unemployment = filter_collection(spending_unemployment, \n",
    "                                     lambda doc: doc.get(\"rate\", 0) > 15.0)\n",
    "print(f\"Found {len(high_unemployment)} records in high-poverty areas\")\n",
    "\n",
    "# Aggregation: Average spending by poverty level\n",
    "print(\"\\n5c. Aggregation: Spending comparison by poverty level\")\n",
    "def categorize_unemployment(doc):\n",
    "    rate = doc.get(\"rate\", 0)\n",
    "    if rate >= 20.0:\n",
    "        return \"very_high\"\n",
    "    elif rate >= 15.0:\n",
    "        return \"high\"\n",
    "    elif rate >= 10.0:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"low\"\n",
    "\n",
    "spending_with_unemp_cat = Collection(\"spending_unemp_categorized\")\n",
    "for doc in spending_unemployment:\n",
    "    new_doc = doc.copy()\n",
    "    new_doc[\"unemployment_category\"] = categorize_unemployment(doc)\n",
    "    spending_with_unemp_cat.insert(new_doc)\n",
    "\n",
    "avg_by_unemployment = aggregate(spending_with_unemp_cat, \"unemployment_category\", \"spend\", \"avg\")\n",
    "print(\"Average spending by poverty category:\")\n",
    "for result in avg_by_unemployment:\n",
    "    print(f\"  {result['unemployment_category']}: ${result['avg(spend)']:.2f}\")\n",
    "\n",
    "# Year-over-year analysis\n",
    "print(\"\\n5d. Spending by year and poverty rate\")\n",
    "year_groups = group_by(spending_unemployment, \"year\")\n",
    "for year, docs in sorted(year_groups.items()):\n",
    "    avg_spend = sum(doc.get(\"spend\", 0) for doc in docs) / len(docs) if docs else 0\n",
    "    avg_poverty = sum(doc.get(\"rate\", 0) for doc in docs) / len(docs) if docs else 0\n",
    "    print(f\"  {year}: Avg spending=${avg_spend:.2f}, Avg poverty rate={avg_poverty:.2f}%\")\n",
    "\n",
    "# Application Question 4: Employment and green purchasing relationship\n",
    "print(\"\\n6. Question 4: How does employment status affect green purchasing behavior?\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Join employment with food spending for detailed analysis\n",
    "print(\"\\n6a. Join: Employment data with food spending\")\n",
    "employment_food = join_collections(employment, food_spending, \"county\", \"county\")\n",
    "print(f\"Joined collection has {len(employment_food)} records\")\n",
    "\n",
    "# Filter: High employment rate areas\n",
    "print(\"\\n6b. Filtering: Counties with employment rate > 90%\")\n",
    "high_emp_areas = filter_collection(employment_food, \n",
    "                                   lambda doc: doc.get(\"employment_rate\", 0) > 90.0)\n",
    "print(f\"Found {len(high_emp_areas)} records in high-employment areas\")\n",
    "\n",
    "# Aggregation: Spending by employment rate ranges\n",
    "print(\"\\n6c. Aggregation: Spending by employment rate ranges\")\n",
    "def categorize_employment_rate(doc):\n",
    "    rate = doc.get(\"employment_rate\", 0)\n",
    "    if rate >= 90:\n",
    "        return \"very_high\"\n",
    "    elif rate >= 85:\n",
    "        return \"high\"\n",
    "    elif rate >= 75:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"low\"\n",
    "\n",
    "spending_with_emp_rate = Collection(\"spending_emp_rate\")\n",
    "for doc in employment_food:\n",
    "    new_doc = doc.copy()\n",
    "    new_doc[\"emp_rate_category\"] = categorize_employment_rate(doc)\n",
    "    spending_with_emp_rate.insert(new_doc)\n",
    "\n",
    "avg_by_emp_rate = aggregate(spending_with_emp_rate, \"emp_rate_category\", \"spend\", \"avg\")\n",
    "print(\"Average spending by employment rate category:\")\n",
    "for result in avg_by_emp_rate:\n",
    "    print(f\"  {result['emp_rate_category']}: ${result['avg(spend)']:.2f}\")\n",
    "\n",
    "# Complex analysis: Employment level and food category\n",
    "print(\"\\n6d. Complex Analysis: Employment level by food category\")\n",
    "emp_category_groups = {}\n",
    "for doc in employment_food:\n",
    "    emp_level = doc.get(\"employment_level\")\n",
    "    category = doc.get(\"category\")\n",
    "    if emp_level and category:\n",
    "        key = (emp_level, category)\n",
    "        if key not in emp_category_groups:\n",
    "            emp_category_groups[key] = []\n",
    "        emp_category_groups[key].append(doc)\n",
    "\n",
    "print(\"Top combinations of employment level and food category:\")\n",
    "sorted_emp_cat = sorted(emp_category_groups.items(), \n",
    "                        key=lambda x: sum(d.get(\"spend\", 0) for d in x[1]), \n",
    "                        reverse=True)\n",
    "for (emp_level, category), docs in sorted_emp_cat[:8]:\n",
    "    total = sum(d.get(\"spend\", 0) for d in docs)\n",
    "    avg_emp_rate = sum(d.get(\"employment_rate\", 0) for d in docs) / len(docs) if docs else 0\n",
    "    print(f\"  {emp_level} employment - {category}: ${total:.2f} (avg emp rate: {avg_emp_rate:.1f}%)\")\n",
    "\n",
    "# Application Question 5: Category analysis\n",
    "print(\"\\n7. Question 5: Spending patterns by food category\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Aggregation: Total spending by category\n",
    "print(\"\\n7a. Aggregation: Total spending by category\")\n",
    "total_by_category = aggregate(food_spending, \"category\", \"spend\", \"sum\")\n",
    "for result in total_by_category:\n",
    "    print(f\"  {result['category']}: ${result['sum(spend)']:.2f}\")\n",
    "\n",
    "# Aggregation: Average spending by category\n",
    "print(\"\\n7b. Aggregation: Average spending by category\")\n",
    "avg_by_category = aggregate(food_spending, \"category\", \"spend\", \"avg\")\n",
    "for result in avg_by_category:\n",
    "    print(f\"  {result['category']}: ${result['avg(spend)']:.2f}\")\n",
    "\n",
    "# Complex query: Category spending by county\n",
    "print(\"\\n7c. Complex Query: Category spending by county (using group by and aggregation)\")\n",
    "county_category_groups = {}\n",
    "for doc in food_spending:\n",
    "    county = doc.get(\"county\")\n",
    "    category = doc.get(\"category\")\n",
    "    key = (county, category)\n",
    "    if key not in county_category_groups:\n",
    "        county_category_groups[key] = []\n",
    "    county_category_groups[key].append(doc)\n",
    "\n",
    "print(\"Top spending combinations:\")\n",
    "sorted_combos = sorted(county_category_groups.items(), \n",
    "                      key=lambda x: sum(d.get(\"spend\", 0) for d in x[1]), \n",
    "                      reverse=True)\n",
    "for (county, category), docs in sorted_combos[:5]:\n",
    "    total = sum(d.get(\"spend\", 0) for d in docs)\n",
    "    print(f\"  {county} - {category}: ${total:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"APPLICATION ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This project implements:\n",
    "\n",
    "1. **Extended JSON Parser**: Handles objects, arrays, nested structures, booleans, and null values\n",
    "2. **CSV Parser**: Custom CSV parser that handles quoted fields and converts data types appropriately\n",
    "3. **Excel Parser**: Custom Excel file parser using openpyxl to load .xlsx files into collections\n",
    "4. **Collection Class**: Stores and manages JSON documents (similar to MongoDB collections)\n",
    "5. **Core Operations**:\n",
    "   - **Filtering**: Select documents based on conditions\n",
    "   - **Projection**: Select specific fields from documents\n",
    "   - **Group By**: Group documents by a key\n",
    "   - **Aggregation**: Compute aggregates (sum, avg, max, min, count) on grouped data\n",
    "   - **Join**: Join two collections on specified keys\n",
    "\n",
    "6. **Data Transformation**: Functions to transform real-world data into format suitable for green purchasing analysis:\n",
    "   - **Consumer Data**: Transforms consumer spending Excel data into food spending format\n",
    "   - **Employment Data**: Transforms employment Excel data into jobs/employment format\n",
    "   - **Unemployment Data**: Transforms unemployment Excel data into unemployment rate format\n",
    "   - **Food Environment Atlas**: Extracts variables related to local foods, farmers markets, direct sales, and specialized stores\n",
    "   - **Employment Indicators**: Creates employment data using income and economic indicators as proxies (employment levels, rates, occupation types, metro status)\n",
    "   - Maps to green purchasing behavior indicators\n",
    "\n",
    "7. **Application**: Green Purchasing Behavior analysis using real data from multiple sources:\n",
    "   - **Consumer spending data** from Excel files (cu-all-detail-2023.xlsx)\n",
    "   - **Employment data** from Excel files (all_data_M_2024.xlsx)\n",
    "   - **Unemployment data** from Excel files (metro-annual-unemployment-rates.xlsx)\n",
    "   - **Food Environment Atlas** data for supplementary analysis\n",
    "   - Analyzes who buys sustainable food (geography)\n",
    "   - Examines income influence on purchasing behavior\n",
    "   - **Analyzes employment status impact** on green purchasing (employment levels, rates, occupation types, metro/nonmetro)\n",
    "   - Studies economic shocks (unemployment/poverty) impact on spending\n",
    "   - Analyzes spending patterns by food category\n",
    "\n",
    "All operations are implemented from scratch without using pandas, json, or csv libraries. The project now uses real data from Excel files and the USDA Food Environment Atlas instead of synthetic sample data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
